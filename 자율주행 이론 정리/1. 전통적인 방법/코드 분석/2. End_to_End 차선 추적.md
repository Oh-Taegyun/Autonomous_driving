``` python
import cv2
import numpy as np
import logging
import math
from keras.models import load_model  # Keras 모델 로드 함수
from hand_coded_lane_follower import HandCodedLaneFollower  # 수동으로 코딩된 차선 추적기 클래스

_SHOW_IMAGE = False  # 이미지를 표시할지 여부를 설정하는 플래그
```

기존 수동 차선 추적의 문제점을 바탕으로 추가적으로 몇개만 더 구현하면 된다. 

``` python
# 이미지를 전처리하는 함수
def img_preprocess(image):
    height, _, _ = image.shape
    image = image[int(height/2):, :, :]  # 이미지의 상단 절반 제거 (차선 추적에 불필요한 부분)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)  # YUV 색 공간으로 변환 (Nvidia 모델에서 권장)
    image = cv2.GaussianBlur(image, (3, 3), 0)  # 가우시안 블러 적용
    image = cv2.resize(image, (200, 66))  # Nvidia 모델의 입력 크기로 이미지 크기 조정 (200x66)
    image = image / 255  # 정규화 (0~1 범위로)
    return image

# 이미지를 화면에 표시하는 함수
def show_image(title, frame, show=_SHOW_IMAGE):
    if show:
        cv2.imshow(title, frame)
```


``` python
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import logging
import numpy as np
from PIL import Image

# End-to-End 방식으로 차선을 추적하는 클래스 정의
class EndToEndLaneFollower(object):
    def __init__(self, car=None, model_path='/home/pi/DeepPiCar/models/lane_navigation/data/model_result/lane_navigation.pth'):
        logging.info('Creating an EndToEndLaneFollower...')

        self.car = car  # 제어할 자동차 객체
        self.curr_steering_angle = 90  # 초기 조향각 설정 (90도는 직진)
        
        # PyTorch 모델 로드
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = torch.load(model_path, map_location=self.device)
        self.model.eval()  # 평가 모드로 설정

    def follow_lane(self, frame):
        # 차선 추적의 메인 진입점
        show_image("orig", frame)

        # 현재 프레임에서 조향각 계산
        self.curr_steering_angle = self.compute_steering_angle(frame)
        logging.debug("curr_steering_angle = %d" % self.curr_steering_angle)

        # 자동차가 존재할 경우 조향각 설정
        if self.car is not None:
            self.car.front_wheels.turn(self.curr_steering_angle)
        
        # 조향각을 시각적으로 표시
        final_frame = display_heading_line(frame, self.curr_steering_angle)
        return final_frame

    def compute_steering_angle(self, frame):
        """ 
        비디오 프레임을 기반으로 직접 조향각을 계산하는 함수
        카메라가 중앙을 향해 보정되었다고 가정합니다.
        """
        preprocessed = self.img_preprocess(frame)  # 프레임 전처리
        X = preprocessed.unsqueeze(0).to(self.device)  # 모델 입력 형태로 변환 및 GPU로 이동
        
        with torch.no_grad():
            steering_angle = self.model(X).item()  # 모델을 통해 예측된 조향각

        logging.debug('new steering angle: %s' % steering_angle)
        return int(steering_angle + 0.5)  # 가장 가까운 정수로 반올림하여 반환
```


### 1. 테스트
---
``` python

############################
# 테스트 함수들
############################

# 정지된 사진으로 테스트하는 함수
def test_photo(file):
    lane_follower = EndToEndLaneFollower()  # End-to-End 방식의 차선 추적기 생성
    frame = cv2.imread(file)  # 파일에서 이미지 읽기
    combo_image = lane_follower.follow_lane(frame)  # 차선 추적
    show_image('final', combo_image, True)  # 최종 이미지 표시
    logging.info("filename=%s, model=%3d" % (file, lane_follower.curr_steering_angle))
    cv2.waitKey(0)
    cv2.destroyAllWindows()

# 비디오 파일로 테스트하는 함수
def test_video(video_file):
    end_to_end_lane_follower = EndToEndLaneFollower()  # End-to-End 방식의 차선 추적기 생성
    hand_coded_lane_follower = HandCodedLaneFollower()  # 수동으로 코딩된 차선 추적기 생성
    cap = cv2.VideoCapture(video_file + '.avi')  # 비디오 파일 열기

    # 비디오 시작 후 첫 번째 몇 프레임을 건너뜁니다.
    for i in range(3):
        _, frame = cap.read()

    video_type = cv2.VideoWriter_fourcc(*'XVID')  # 비디오 코덱 설정
    video_overlay = cv2.VideoWriter("%s_end_to_end.avi" % video_file, video_type, 20.0, (320, 240))  # 출력 비디오 생성
    try:
        i = 0
        while cap.isOpened():
            _, frame = cap.read()  # 비디오 프레임 읽기
            frame_copy = frame.copy()  # 프레임 복사
            logging.info('Frame %s' % i)
            combo_image1 = hand_coded_lane_follower.follow_lane(frame)  # 수동 차선 추적
            combo_image2 = end_to_end_lane_follower.follow_lane(frame_copy)  # End-to-End 차선 추적

            # 두 차선 추적기의 조향각 차이 계산 및 출력
            diff = end_to_end_lane_follower.curr_steering_angle - hand_coded_lane_follower.curr_steering_angle
            logging.info("desired=%3d, model=%3d, diff=%3d" %
                         (hand_coded_lane_follower.curr_steering_angle,
                          end_to_end_lane_follower.curr_steering_angle,
                          diff))

            video_overlay.write(combo_image2)  # 비디오에 결과 저장
            cv2.imshow("Hand Coded", combo_image1)  # 수동 차선 추적 결과 표시
            cv2.imshow("Deep Learning", combo_image2)  # End-to-End 차선 추적 결과 표시

            i += 1
            if cv2.waitKey(1) & 0xFF == ord('q'):  # 'q' 키 입력 시 종료
                break
    finally:
        cap.release()  # 비디오 리소스 해제
        video_overlay.release()
        cv2.destroyAllWindows()  # 모든 창 닫기

```