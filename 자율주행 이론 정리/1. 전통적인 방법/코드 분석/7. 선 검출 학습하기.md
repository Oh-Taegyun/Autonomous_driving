> https://developer.nvidia.com/blog/deep-learning-self-driving-cars/

모델은 자율주행과 같은 응용 분야에서 흔히 사용되는 **NVIDIA의 자율주행 차량용 신경망(NVIDIA Self-Driving Car Neural Network)** 을 기반으로 만들자. 

이 모델은 특히 자율주행 차량의 주행 제어를 위해 카메라로부터 얻은 도로 영상을 입력으로 받아 차량의 **조향각(turn angle)** 을 예측하도록 학습된다. 이를 통해 차량이 스티어링 휠을 얼마나 돌려야 할지 결정하게 된다.

### 모델 설명
---
이 모델은 자율주행 시스템의 **운전자 보조 시스템**에 적합하도록 설계된 **회귀(Regression)** 모델이다. 

1. **입력 형상**:
    - `(66, 200, 3)`의 입력 형상을 가지며, 이는 자율주행에 사용되는 **전방 카메라 이미지**의 전처리된 형태입니다.
    - 66x200은 이미지의 높이와 너비이며, `3`은 RGB 채널을 의미합니다.

2. **Convolutional Layers (합성곱 층)**:
    - **Conv2D 층**들은 이미지의 시각적 특징을 추출하기 위한 합성곱 계층으로 이루어져 있습니다.
    - 각 Conv2D 계층은 `ELU(Exponential Linear Unit)` 활성화 함수를 사용하며, 이는 **ReLU**와 비슷하지만 부정적인 입력에 대해 점진적으로 감쇠하는 방식으로 동작합니다.
    - **Dropout(0.2)** 은 과적합(overfitting)을 방지하기 위해 추가된 것으로, 학습 중 일부 뉴런을 무작위로 제외하여 네트워크가 특정 패턴에 과도하게 적응하는 것을 방지합니다.
    - 합성곱 층들은 이미지에서 고유의 특징들을 추출하며, `strides`를 통해 입력 데이터의 다운샘플링도 수행합니다.

3. **Flatten 층**:
    - **Flatten**은 합성곱 층을 통해 얻은 다차원 피처맵을 1차원으로 변환하여 Fully Connected Layer에 전달합니다.

4. **Fully Connected Layers (완전 연결 층)**:
    - **Dense 층**들은 차량의 조향 각도를 결정하기 위해 이미지 특징을 조합하고 가중치를 학습합니다.
    - 여러 개의 Dense 층은 특징들의 비선형 조합을 통해 최적의 조향 각도를 예측하는 역할을 합니다.
    - 이 모델은 `100`, `50`, `10` 개의 뉴런을 가지는 Fully Connected 층을 순차적으로 구성하고 있으며, 각 층에서도 `ELU` 활성화를 사용합니다.

5. **Output Layer**:
    - 마지막 **Dense(1)** 층은 예측할 조향 각도 값을 출력합니다. 출력값은 차량이 좌회전(왼쪽)으로 조향할지, 우회전(오른쪽)으로 조향할지, 또는 직진할지를 나타내는 **조향 각도**입니다.
    - `1`개의 뉴런을 사용하여 회귀 문제의 결과를 나타내기 때문에 활성화 함수는 사용하지 않습니다.

6. **컴파일 및 손실 함수**:
    - **MSE (Mean Squared Error)**: 회귀 문제에서 자주 사용되는 손실 함수로, 예측한 조향각과 실제 각도 간의 오차 제곱합을 최소화하는 것을 목표로 합니다.
    - **Adam Optimizer**: 학습을 최적화하기 위해 **Adam** 옵티마이저를 사용합니다. `lr=1e-3`로 설정된 **학습률**은 모델이 가중치를 얼마나 빠르게 조정할지 결정합니다.

``` python
import torch
import torch.nn as nn
import torch.optim as optim

class NvidiaModel(nn.Module):
    def __init__(self):
        super(NvidiaModel, self).__init__()
        
        # Convolutional Layers
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 24, kernel_size=5, stride=2),  # input channels = 3 (RGB)
            nn.ELU(),
            nn.Conv2d(24, 36, kernel_size=5, stride=2),
            nn.ELU(),
            nn.Conv2d(36, 48, kernel_size=5, stride=2),
            nn.ELU(),
            nn.Conv2d(48, 64, kernel_size=3),
            nn.ELU(),
            nn.Dropout(0.2),  # Dropout layer for robustness
            nn.Conv2d(64, 64, kernel_size=3),
            nn.ELU()
        )
        
        # Fully Connected Layers
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(0.2),  # Dropout layer for robustness
            nn.Linear(64 * 3 * 10, 100),  # flattened output size of conv layers
            nn.ELU(),
            nn.Linear(100, 50),
            nn.ELU(),
            nn.Linear(50, 10),
            nn.ELU(),
            nn.Linear(10, 1)  # Output layer for the steering angle
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x

# Model, loss function, and optimizer
model = NvidiaModel()

# Mean Squared Error loss, as this is a regression problem
criterion = nn.MSELoss()

# Adam optimizer with learning rate 1e-3
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# Example usage
# Assuming input tensor is of shape (batch_size, 3, 66, 200)
# where (3, 66, 200) represents the (channels, height, width) of the image
input_tensor = torch.randn(8, 3, 66, 200)  # batch size of 8 for demonstration
output = model(input_tensor)
print(output.shape)  # Should output: torch.Size([8, 1])

```

