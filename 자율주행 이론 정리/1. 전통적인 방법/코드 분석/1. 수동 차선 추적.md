전통적인 방법으로 차선을 추적하는 코드를 분석해보자!

``` python
import cv2
import numpy as np
import logging
import math
import datetime
import sys

_SHOW_IMAGE = False  # 이미지를 표시할지 여부를 설정하는 플래그

def show_image(title, frame, show=_SHOW_IMAGE):
    if show:
        cv2.imshow(title, frame)
```


### 1. 유틸리티 함수
---
``` python
def display_lines(frame, lines, line_color=(0, 255, 0), line_width=10):
	# 역할: 감지된 선분(또는 차선)을 프레임 위에 시각적으로 표시.
	# lines의 각 선분을 주어진 색상과 두께로 그린 뒤 원본 프레임과 합성.
    # frame: 원본 프레임 (이미지)
    # lines: 선분 리스트 (각 선분은 [[x1, y1, x2, y2]] 형식으로 주어짐)
    # line_color: 선분의 색상 (기본값은 초록색)
    # line_width: 선분의 두께

    # 원본 프레임과 같은 크기의 빈 이미지 생성 (모든 픽셀 값이 0)
    line_image = np.zeros_like(frame)

    if lines is not None:  # 감지된 선분이 있는 경우
        for line in lines:  # 각 선분에 대해
            for x1, y1, x2, y2 in line:  # 선분 좌표를 추출
                # 빈 이미지 위에 선분 그리기
                cv2.line(line_image, (x1, y1), (x2, y2), line_color, line_width)

    # 원본 프레임과 선분 이미지를 가중합하여 합성
    line_image = cv2.addWeighted(frame, 0.8, line_image, 1, 1)
    return line_image

```

``` python
def display_heading_line(frame, steering_angle, line_color=(0, 0, 255), line_width=5):
	# 역할: 조향각(steering angle)을 시각적으로 표시하는 방향선을 프레임 위에 그리기.
	# 현재 조향각을 기반으로 방향선을 계산하고, 이를 원본 프레임에 표시.
    # frame: 원본 프레임 (이미지)
    # steering_angle: 조향각 (0도는 왼쪽, 90도는 직진, 180도는 오른쪽)
    # line_color: 방향선의 색상 (기본값은 빨간색)
    # line_width: 방향선의 두께

    # 원본 프레임과 같은 크기의 빈 이미지 생성
    heading_image = np.zeros_like(frame)

    # 프레임의 크기 추출
    height, width, _ = frame.shape

    # 조향각을 라디안으로 변환
    steering_angle_radian = steering_angle / 180.0 * math.pi

    # 시작점 (프레임 하단 중앙)
    x1 = int(width / 2)
    y1 = height

    # 끝점 (조향각을 기반으로 계산)
    x2 = int(x1 - height / 2 / math.tan(steering_angle_radian))
    y2 = int(height / 2)

    # 빈 이미지 위에 방향선 그리기
    cv2.line(heading_image, (x1, y1), (x2, y2), line_color, line_width)

    # 원본 프레임과 방향선 이미지를 가중합하여 합성
    heading_image = cv2.addWeighted(frame, 0.8, heading_image, 1, 1)

    return heading_image

```

``` python
def length_of_line_segment(line):
	# 역할: 선분의 길이를 계산.
    # line: 선분의 좌표 (x1, y1, x2, y2)
    x1, y1, x2, y2 = line

    # 두 점 간의 유클리드 거리 계산
    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
```

``` python
def make_points(frame, line):
	# 역할: 주어진 기울기(slope)와 절편(intercept)을 사용하여 선분의 두 점을 계산.
	# 이미지의 하단과 중간 높이를 기준으로 선분의 두 점 `(x1, y1)`과 `(x2, y2)` 계산.
    # frame: 원본 프레임 (이미지)
    # line: 선의 기울기(slope)와 절편(intercept) (예: (m, b))

    height, width, _ = frame.shape  # 프레임 크기 추출
    slope, intercept = line  # 선의 기울기와 절편 추출

    # y1: 프레임 하단 (차선의 시작점)
    y1 = height

    # y2: 프레임 중간 (차선의 끝점)
    y2 = int(y1 * 1 / 2)

    # x1: y1에 대응하는 x 좌표
    x1 = max(-width, min(2 * width, int((y1 - intercept) / slope)))

    # x2: y2에 대응하는 x 좌표
    x2 = max(-width, min(2 * width, int((y2 - intercept) / slope)))

    # 계산된 선분의 두 점을 반환
    return [[x1, y1, x2, y2]]

```


### 2. detect_lane(frame)
---
``` python
def detect_lane(frame):
    # Lane Detection 단계에서 사용하는 코드 
    # 입력은 비디오 프레임, 출력은 감지된 차선 라인의 정보과 시각화된 이미지이다. 
    
    # 1. 엣지 감지 수행
    edges = detect_edges(frame)
    show_image('edges', edges)

    # 2. 관심 영역(ROI)을 설정하여 도로 부분만 유지
    cropped_edges = region_of_interest(edges)
    show_image('edges cropped', cropped_edges)

    # 3. 허프 변환을 통해 선분 감지
    line_segments = detect_line_segments(cropped_edges)
    line_segment_image = display_lines(frame, line_segments)
    show_image("line segments", line_segment_image)

    # 4. 감지된 선분을 평균화하여 차선 생성
    lane_lines = average_slope_intercept(frame, line_segments)
    lane_lines_image = display_lines(frame, lane_lines)
    show_image("lane lines", lane_lines_image)

    return lane_lines, lane_lines_image
```

``` python
def detect_edges(frame):
    # 차선에 해당하는 엑지를 감지하기 위한 프레임 처리 기법 
    # 1. BGR 이미지를 HSV 색 공간으로 변환
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # BGR 색 공간을 HSV로 변환
    show_image("hsv", hsv) # 변환된 이미지 출력 

    # 2. 파란색 범위를 정의하고 마스크 생성
    # 왜 파란색 범위를 정의할까? 
    lower_blue = np.array([30, 40, 0]) # 색상(H), 채도(S), 명도(V)
    upper_blue = np.array([150, 255, 255])
    mask = cv2.inRange(hsv, lower_blue, upper_blue) # 파란색 마스크 설정
    show_image("blue mask", mask) 

    # 3. Canny Edge Detection 적용
    edges = cv2.Canny(mask, 200, 400) 
    return edges
```

이거 중간에 왜 파란 마스크를 설정할까? 

그 이유는 파란색 마스크를 설정하는 이유는 주로 차선 인식과 관련이 있기 때문이다. 많은 도로에서 **차선 표시는 파란색이나 흰색으로 되어 있는 경우가 많기 때문**이다. 이와 같은 작업에서는 도로의 차선을 정확히 감지하기 위해 해당 색상의 차선을 강조하고, 불필요한 배경 정보를 제거하여 차선만을 효과적으로 추출하는 것이 중요한데, HSV 색 공간에서 특정 색상 범위를 설정하는 것이 이를 간단하게 구현할 수 있는 방법이다.

HSV 색 공간은 색상, 채도, 명도를 별도로 제어할 수 있어 특정 색상을 쉽게 필터링할 수 있으며, 이러한 특성 덕분에 차선 인식 작업에서는 자주 사용된다. `cv2.inRange()` 함수를 사용하여 특정 색상 범위를 설정한 후 마스크를 적용함으로써 이미지에서 해당 색상에 해당하는 영역만 남기고 나머지는 모두 제거할 수 있다.

- 도로 차선은 파란색, 흰색, 또는 노란색으로 표시되는 경우가 많다. 이 예제에서는 파란색 차선을 인식하는 것으로 가정하고 있으며, HSV 색 공간에서 **Hue** 값을 통해 파란색에 해당하는 색상 범위를 지정한다.

- 만약 도로가 파란색 차선으로 표시되어 있다면, 다른 배경 색상이나 불필요한 객체들(예: 차량, 표지판 등)을 제거하고 차선만 남길 수 있도록 특정 색상에 대한 마스크를 설정하는 것이 효과적이다.

그럼 만약 다른 색상의 차선을 인식하려면 어떻게 해야할까?

만약 도로에서 파란색이 아닌 다른 색상의 차선을 인식하고 싶다면, `lower_blue`와 `upper_blue`를 차선의 색상에 맞게 수정하면 된다. 예를 들어, 흰색이나 노란색 차선을 추적하려면 그에 맞는 HSV 값 범위를 설정해야 한다.

``` python
# 예를 들어 흰색 차선을 인식하려면:
lower_white = np.array([0, 0, 200])
upper_white = np.array([180, 25, 255])
mask = cv2.inRange(hsv, lower_white, upper_white)
```

### 3. region_of_interest(canny)
---
``` python
def region_of_interest(canny):
    # 역할: 관심 영역(ROI) 마스크를 생성하여 도로 영역만 분석.
    # 프레임의 하단 부분(도로 영역)을 유지하고 상단 부분을 제거.
    
    height, width = canny.shape
    mask = np.zeros_like(canny)

    # 다각형 형태로 ROI 정의 (프레임 하단 절반)
    polygon = np.array([[
        (0, height * 1 / 2),
        (width, height * 1 / 2),
        (width, height),
        (0, height),
    ]], np.int32)

    # ROI 영역을 흰색(255)으로 채우고 나머지는 검정색(0)
    cv2.fillPoly(mask, polygon, 255)
    show_image("mask", mask)

    # ROI 마스크와 엣지 이미지를 결합
    masked_image = cv2.bitwise_and(canny, mask)
    return masked_image
```

### 4. detect_line_segments(cropped_edges)
---
``` python
def detect_line_segments(cropped_edges):
    # 허프 변환 파라미터 설정
    # 역할: 허프 변환을 사용하여 엣지에서 선분 감지. (영상에서 직선을 검출하기 위한 알고리즘)
    # 감지된 선분의 정보를 반환 (각 선분은 두 점 (x1, y1)과 (x2, y2)로 표현).

    rho = 1  # 거리 정밀도 (1 픽셀 단위)
    angle = np.pi / 180  # 각도 정밀도 (1도 단위)
    min_threshold = 10  # 선이 되기 위한 최소 허프 공간 누적 값

    # 허프 변환으로 선분 탐지
    line_segments = cv2.HoughLinesP(
        cropped_edges, rho, angle, min_threshold, np.array([]),
        minLineLength=8, maxLineGap=4
    )

    return line_segments
```


### 5. average_slope_intercept(frame, line_segments)
---
``` python
def average_slope_intercept(frame, line_segments):
    # 감지된 선분을 하나 또는 두 개의 차선으로 결합.
    # 선분의 기울기와 절편을 평균화하여 차선을 생성.
    # 기울기가 음수(< 0)인 선은 왼쪽 차선, 양수(> 0)인 선은 오른쪽 차선으로 분류.
    # line_segments는 여러 직선의 선분들을 포함하는 리스트입니다. 예를 들어, line_segments의 각 요소는 다음과 같은 형식을 가집니다.
    # ex) [[x1, y1, x2, y2]]

    lane_lines = []
    if line_segments is None:
        logging.info('No line segments detected') # 감지된 선분이 없다. 
        return lane_lines

    height, width, _ = frame.shape
    left_fit = []
    right_fit = []

    # 화면의 왼쪽과 오른쪽 영역 경계 설정
    boundary = 1/3
    left_region_boundary = width * (1 - boundary)
    right_region_boundary = width * boundary

    for line_segment in line_segments:
        for x1, y1, x2, y2 in line_segment:
            if x1 == x2:  # 수직선(기울기 무한대)은 스킵
                continue
            fit = np.polyfit((x1, x2), (y1, y2), 1) # 1차로 직선을 그린다. 
            slope, intercept = fit # ax+b
            if slope < 0:  # 왼쪽 차선
                if x1 < left_region_boundary and x2 < left_region_boundary: # 두놈 다 왼쪽이면 왼쪽에 존재 
                    left_fit.append((slope, intercept))
            else:  # 오른쪽 차선 
                if x1 > right_region_boundary and x2 > right_region_boundary: # 두놈 다 오른쪽이면 오른쪽에 존재 
                    right_fit.append((slope, intercept))

    # 왼쪽, 오른쪽 차선을 평균화
    if len(left_fit) > 0:
        left_fit_average = np.average(left_fit, axis=0)
        lane_lines.append(make_points(frame, left_fit_average))

    if len(right_fit) > 0:
        right_fit_average = np.average(right_fit, axis=0)
        lane_lines.append(make_points(frame, right_fit_average))

    return lane_lines
```

1. `numpy.polyfit()` ![[Pasted image 20241201215217.png]]![[Pasted image 20241201215238.png]]

2. ![[Pasted image 20241201215308.png]]

3. ![[Pasted image 20241201215327.png]]

4. 예를 들어:
	- 차가 도로를 따라 직진한다고 가정할 때, 카메라로 보는 화면에서 왼쪽 차선은 화면의 왼쪽 아래에서 위쪽으로 올라가는 방향으로 기울어져 있다. 이 경우, 왼쪽 차선의 기울기는 음수가 된다.
	- 반대로, 오른쪽 차선은 오른쪽 아래에서 위쪽으로 올라가는 방향으로 기울어져 있으므로, 기울기는 양수가 된다.


### 6. compute_steering_angle(frame, lane_lines)
---
역할: 감지된 차선을 기반으로 조향각을 계산.
세부 동작: 차선의 중심점을 계산하여 차량이 이동할 방향을 결정.

``` python
def compute_steering_angle(frame, lane_lines):
    # 감지된 차선을 기반으로 조항각을 계산
    # 차선의 중심점을 계산해 차량이 이동할 방향을 결정 
    if len(lane_lines) == 0:
        return 90  # 차선이 없으면 기본적으로 직진

    height, width, _ = frame.shape

    if len(lane_lines) == 1:  # 하나의 차선만 감지된 경우
        x1, _, x2, _ = lane_lines[0][0]
        x_offset = x2 - x1
    else:  # 두 개의 차선이 감지된 경우
        _, _, left_x2, _ = lane_lines[0][0]
        _, _, right_x2, _ = lane_lines[1][0]
        mid = width / 2
        x_offset = (left_x2 + right_x2) / 2 - mid

    y_offset = height / 2
    angle_to_mid_radian = math.atan(x_offset / y_offset)
    angle_to_mid_deg = int(angle_to_mid_radian * 180.0 / math.pi)
    steering_angle = angle_to_mid_deg + 90
    return steering_angle
```


### 7. tabilize_steering_angle()
---
``` python
def stabilize_steering_angle(curr_steering_angle, new_steering_angle, num_of_lane_lines, max_angle_deviation_two_lines=5, max_angle_deviation_one_lane=1):
    """
    이전 조향각을 사용하여 조향각을 안정화하는 함수
    새 각도가 현재 각도와 너무 다르면 최대 편차각으로만 변경
    """

    if num_of_lane_lines == 2:
        max_angle_deviation = max_angle_deviation_two_lines
    else:
        max_angle_deviation = max_angle_deviation_one_lane

    angle_deviation = new_steering_angle - curr_steering_angle
    if abs(angle_deviation) > max_angle_deviation:
        stabilized_steering_angle = int(curr_steering_angle + max_angle_deviation * angle_deviation / abs(angle_deviation))
    else:
        stabilized_steering_angle = new_steering_angle

    logging.info('Proposed angle: %s, stabilized angle: %s' % (new_steering_angle, stabilized_steering_angle))

    return stabilized_steering_angle
```


### 8. 한번 써보자
---
``` python
# 수동으로 코딩된 차선 추적기 클래스
class HandCodedLaneFollower(object):
    def __init__(self, car=None):
        logging.info('Creating a HandCodedLaneFollower...')
        self.car = car  # 자동차 객체
        self.curr_steering_angle = 90  # 초기 조향각 설정 (90도는 직진)

    def follow_lane(self, frame):
        # 차선 추적의 메인 진입점
        show_image("orig", frame)
        # 차선을 감지하고 조향 수행
        lane_lines, frame = detect_lane(frame) # 차선 라인, 이미지에 적용된 상태
        final_frame = self.steer(frame, lane_lines)
        return final_frame

    def steer(self, frame, lane_lines):
        logging.debug('steering...')
        if len(lane_lines) == 0:
            logging.error('No lane lines detected, nothing to do.')
            return frame

        # 감지된 차선을 기반으로 새로운 조향각 계산
        new_steering_angle = compute_steering_angle(frame, lane_lines)
        # 감지된 차선 안정화하기 
        self.curr_steering_angle = stabilize_steering_angle(
            self.curr_steering_angle, new_steering_angle, len(lane_lines))

        # 자동차가 존재할 경우 조향각 설정
        if self.car is not None:
            self.car.front_wheels.turn(self.curr_steering_angle)

        # 조향각을 시각적으로 표시
        curr_heading_image = display_heading_line(frame, self.curr_steering_angle)
        show_image("heading", curr_heading_image)

        return curr_heading_image
```


### 9. 테스트
---
``` python
def test_photo(file):
    # file: 처리할 이미지 파일 경로

    # 1. HandCodedLaneFollower 객체 생성
    lane_follower = HandCodedLaneFollower()

    # 2. 입력 이미지 읽기
    frame = cv2.imread(file)

    # 3. 차선 추적 수행
    combo_image = lane_follower.follow_lane(frame)

    # 4. 최종 결과 이미지 표시
    show_image('final', combo_image, True)

    # 5. 키 입력 대기 후 모든 창 닫기
    cv2.waitKey(0)
    cv2.destroyAllWindows()

```
- **역할**:
    - 정지된 이미지 파일을 입력으로 받아 차선 추적을 수행.
    - 결과 이미지를 표시하고, 조향각이 시각화된 이미지를 확인.
    
- **세부 동작**:
    - 입력 이미지를 읽고 `HandCodedLaneFollower` 객체를 사용해 차선 추적 수행.
    - 결과 이미지를 OpenCV 창에서 표시.


``` python
def test_video(video_file):
    # video_file: 처리할 비디오 파일 경로 (확장자 없이 경로만 입력)

    # 1. HandCodedLaneFollower 객체 생성
    lane_follower = HandCodedLaneFollower()

    # 2. 비디오 파일 열기
    cap = cv2.VideoCapture(video_file + '.avi')

    # 3. 비디오의 첫 몇 프레임 건너뜀 (필요시 초기화)
    for i in range(3):
        _, frame = cap.read()

    # 4. 비디오 출력 설정
    video_type = cv2.VideoWriter_fourcc(*'XVID')  # 코덱 설정 (XVID 사용)
    video_overlay = cv2.VideoWriter(
        "%s_overlay.avi" % (video_file), video_type, 20.0, (320, 240)
    )  # 출력 파일명과 속성 지정

    try:
        i = 0  # 프레임 인덱스
        while cap.isOpened():  # 비디오 스트림이 열려 있는 동안 반복
            # 5. 현재 프레임 읽기
            _, frame = cap.read()

            # 비디오의 끝에 도달하면 중단
            if frame is None:
                break

            print('frame %s' % i)  # 현재 프레임 번호 출력

            # 6. 차선 추적 수행
            combo_image = lane_follower.follow_lane(frame)

            # 7. 프레임 저장 (원본 및 결과 이미지)
            cv2.imwrite(
                "%s_%03d_%03d.png" % (video_file, i, lane_follower.curr_steering_angle),
                frame,
            )
            cv2.imwrite("%s_overlay_%03d.png" % (video_file, i), combo_image)

            # 8. 결과 프레임을 비디오에 기록
            video_overlay.write(combo_image)

            # 9. 결과 이미지를 화면에 표시
            cv2.imshow("Road with Lane line", combo_image)

            i += 1  # 프레임 인덱스 증가

            # 10. 'q' 키를 누르면 중단
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    finally:
        # 11. 비디오 파일 및 리소스 해제
        cap.release()
        video_overlay.release()
        cv2.destroyAllWindows()

```

- **역할**:
    - 비디오 파일을 입력으로 받아 프레임 단위로 차선 추적을 수행.
    - 추적 결과를 화면에 표시하고, 결과를 새로운 비디오 파일로 저장.

- **세부 동작**:
    - 비디오 파일을 열고, `HandCodedLaneFollower`를 사용해 각 프레임에서 차선 추적 수행.
    - 결과 프레임을 파일로 저장하고, OpenCV 창에서 표시.

- **왜 몇 프레임을 건너뛰는가?**
    - 비디오 시작 시 불필요한 초기화 프레임(흑백 전환 등)을 제거하기 위함.