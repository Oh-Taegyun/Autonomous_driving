``` python
import cv2
import logging
import datetime
import time
from PIL import Image
from traffic_objects import *  # 교통 관련 객체 클래스 임포트

_SHOW_IMAGE = False  # 이미지를 표시할지 여부를 설정하는 플래그
```


### 1. class ObjectsOnRoadProcessor(object):
---
``` python
class ObjectsOnRoadProcessor(object):
    """
    도로 위의 객체(교통 신호 및 사람)를 감지하고,
    자동차의 속도와 조향을 제어하는 클래스.
    """

    def __init__(self,
                 car=None,
                 speed_limit=40,
                 model='/home/pi/DeepPiCar/models/object_detection/data/model_result/road_signs_quantized_edgetpu.tflite',
                 label='/home/pi/DeepPiCar/models/object_detection/data/model_result/road_sign_labels.txt',
                 width=640,
                 height=480):
        """
        초기화 함수
        - car: 자동차 객체 (자동차 제어를 위해 사용)
        - speed_limit: 기본 속도 제한
        - model: 객체 감지에 사용할 Edge TPU TFLite 모델 경로
        - label: 객체 라벨 정보가 포함된 파일 경로
        - width, height: 프레임의 가로/세로 크기
        """

        logging.info('Creating a ObjectsOnRoadProcessor...')

        # 입력 이미지 크기 저장
        self.width = width
        self.height = height

        # 자동차 관련 설정
        self.car = car
        self.speed_limit = speed_limit  # 속도 제한
        self.speed = speed_limit  # 현재 속도

        # 객체 라벨 초기화
        with open(label, 'r') as f:
            # 라벨 파일 읽어오기 (ID와 이름으로 구성된 딕셔너리 생성)
            pairs = (l.strip().split(maxsplit=1) for l in f.readlines())
            self.labels = dict((int(k), v) for k, v in pairs)

        # Edge TPU 모델 초기화
        logging.info('Initialize Edge TPU with model %s...' % model)
        self.engine = edgetpu.detection.engine.DetectionEngine(model)  # Edge TPU 엔진 로드
        self.min_confidence = 0.30  # 객체 감지 최소 신뢰도
        self.num_of_objects = 3  # 최대 감지 객체 수
        logging.info('Initialize Edge TPU with model done.')

        # OpenCV 시각화 설정
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        self.bottomLeftCornerOfText = (10, height - 10)  # FPS 표시 위치
        self.fontScale = 1
        self.fontColor = (255, 255, 255)  # 흰색 텍스트
        self.boxColor = (0, 0, 255)  # 빨간색 경계 상자
        self.boxLineWidth = 1
        self.lineType = 2
        self.annotate_text = ""
        self.annotate_text_time = time.time()
        self.time_to_show_prediction = 1.0  # 경계 상자 표시 시간 (초)

        # 감지할 도로 객체 정의
        self.traffic_objects = {
            0: GreenTrafficLight(),  # 녹색 신호등
            1: Person(),             # 사람
            2: RedTrafficLight(),    # 적색 신호등
            3: SpeedLimit(25),       # 속도 제한 25
            4: SpeedLimit(40),       # 속도 제한 40
            5: StopSign()            # 정지 표지판
        }

```


``` python
    def process_objects_on_road(self, frame):
        """
        도로 위의 객체를 처리하는 메인 함수.
        - 객체 감지 수행
        - 감지된 객체에 따라 자동차 제어
        """
        logging.debug('Processing objects.................................')
        objects, final_frame = self.detect_objects(frame)  # 객체 감지
        self.control_car(objects)  # 객체 기반 자동차 제어
        logging.debug('Processing objects END..............................')

        return final_frame
```


``` python
    def control_car(self, objects):
        """
        감지된 객체에 따라 자동차를 제어하는 함수.
        """
        logging.debug('Control car...')
        car_state = {"speed": self.speed_limit, "speed_limit": self.speed_limit}  # 초기 자동차 상태 설정

        if len(objects) == 0:
            logging.debug('No objects detected, drive at speed limit of %s.' % self.speed_limit)

        contain_stop_sign = False  # 정지 표지판이 있는지 여부

        # 감지된 각 객체에 대해 처리
        for obj in objects:
            obj_label = self.labels[obj.label_id]  # 객체의 라벨 이름 가져오기
            processor = self.traffic_objects[obj.label_id]  # 해당 객체에 대한 처리기 가져오기

            # 객체가 가까이에 있는 경우에만 처리
            if processor.is_close_by(obj, self.height):
                processor.set_car_state(car_state)  # 객체에 따라 자동차 상태 설정
            else:
                logging.debug("[%s] object detected, but it is too far, ignoring. " % obj_label)

            # 정지 표지판이 있는지 확인
            if obj_label == 'Stop':
                contain_stop_sign = True

        # 정지 표지판이 없는 경우 정지 상태 해제
        if not contain_stop_sign:
            self.traffic_objects[5].clear()

        # 자동차 상태에 따라 주행 재개
        self.resume_driving(car_state)

```


``` python
    def resume_driving(self, car_state):
        """
        자동차 주행을 재개하는 함수.
        - car_state: 자동차 상태 정보 (속도 및 속도 제한)
        """
        old_speed = self.speed  # 이전 속도 저장
        self.speed_limit = car_state['speed_limit']  # 새로운 속도 제한 설정
        self.speed = car_state['speed']  # 새로운 속도 설정

        if self.speed == 0:  # 정지 상태인 경우
            self.set_speed(0)
        else:  # 속도 제한에 따라 속도 설정
            self.set_speed(self.speed_limit)
        logging.debug('Current Speed = %d, New Speed = %d' % (old_speed, self.speed))

        if self.speed == 0:  # 완전 정지 상태라면 1초 대기
            logging.debug('full stop for 1 seconds')
            time.sleep(1)

```


``` python
    def set_speed(self, speed):
        """
        자동차 속도를 설정하는 함수.
        """
        self.speed = speed
        if self.car is not None:  # 자동차 객체가 있을 경우
            logging.debug("Actually setting car speed to %d" % speed)
            self.car.back_wheels.speed = speed  # 자동차 속도 설정

```


``` python
    def detect_objects(self, frame):
        """
        객체 감지를 수행하고 감지된 객체를 시각적으로 표시.
        """
        logging.debug('Detecting objects...')

        # 1. 이미지 RGB 변환 및 PIL 형식으로 변환
        start_ms = time.time()
        frame_RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img_pil = Image.fromarray(frame_RGB)

        # 2. Edge TPU로 객체 감지 수행
        objects = self.engine.DetectWithImage(
            img_pil, threshold=self.min_confidence, keep_aspect_ratio=True,
            relative_coord=False, top_k=self.num_of_objects
        )

        if objects:  # 감지된 객체가 있을 경우
            for obj in objects:
                height = obj.bounding_box[1][1] - obj.bounding_box[0][1]
                width = obj.bounding_box[1][0] - obj.bounding_box[0][0]
                logging.debug("%s, %.0f%% w=%.0f h=%.0f" % (
                    self.labels[obj.label_id], obj.score * 100, width, height
                ))

                # 경계 상자 좌표 계산
                box = obj.bounding_box
                coord_top_left = (int(box[0][0]), int(box[0][1]))
                coord_bottom_right = (int(box[1][0]), int(box[1][1]))

                # 경계 상자와 라벨 표시
                cv2.rectangle(frame, coord_top_left, coord_bottom_right, self.boxColor, self.boxLineWidth)
                annotate_text = "%s %.0f%%" % (self.labels[obj.label_id], obj.score * 100)
                coord_top_left = (coord_top_left[0], coord_top_left[1] + 15)
                cv2.putText(frame, annotate_text, coord_top_left, self.font, self.fontScale, self.boxColor, self.lineType)

        else:
            logging.debug('No object detected')

        elapsed_ms = time.time() - start_ms  # 처리 시간 계산

        # FPS 계산 및 표시
        annotate_summary = "%.1f FPS" % (1.0 / elapsed_ms)
        logging.debug(annotate_summary)
        cv2.putText(frame, annotate_summary, self.bottomLeftCornerOfText, self.font, self.fontScale, self.fontColor, self.lineType)

        return objects, frame

```